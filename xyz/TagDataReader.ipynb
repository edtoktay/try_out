{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3ac394-55a2-4dff-ae7c-28a847114281",
   "metadata": {},
   "source": [
    "## Data Reader\n",
    "\n",
    "Reads data from given locations excel file and persist to raw data table with status and persists message to queue about records to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27f97c4-453f-4eb8-8344-60298fe5d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data-reader-requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data-reader-requirements.txt\n",
    "pandas==2.2.1\n",
    "psycopg2==2.9.9\n",
    "pika==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f920327-4726-4fc9-870a-8a62b8003f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.1 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from -r data-reader-requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: psycopg2==2.9.9 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from -r data-reader-requirements.txt (line 2)) (2.9.9)\n",
      "Requirement already satisfied: pika==1.3.2 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from -r data-reader-requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from pandas==2.2.1->-r data-reader-requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from pandas==2.2.1->-r data-reader-requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from pandas==2.2.1->-r data-reader-requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from pandas==2.2.1->-r data-reader-requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/deniz.toktay/Development/Lang/anaconda3/envs/genAI/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1->-r data-reader-requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r data-reader-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbaca3b-435c-4575-b99c-2d93d75b9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pika\n",
    "import json\n",
    "import sql_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18d450b-0de2-4b7a-9897-e1d478dd635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<METHOD(['channel_number=1', 'frame_type=1', \"method=<Queue.DeclareOk(['consumer_count=0', 'message_count=0', 'queue=new_data'])>\"])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mq_connection = pika.BlockingConnection(\n",
    "    pika.ConnectionParameters('172.16.238.20'))\n",
    "channel = mq_connection.channel()\n",
    "channel.queue_declare(queue='new_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db04143d-1333-45ef-b33a-176cdb199496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_name(excel_to_read):\n",
    "    return 'Generated/' + excel_to_read + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8008f73-2a36-40cd-bc25-fc71c97735b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel(file_name):\n",
    "    return pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e620232-2996-4aba-9a9c-a90c6e155448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_message(tagname, batch_id):\n",
    "    cfg = sql_operations.get_configurations_of_tag(tagname)\n",
    "    if cfg is not None:\n",
    "        cfg_message = {\n",
    "            'ConfigId': cfg['ConfigId'],\n",
    "            'BatchId': batch_id,\n",
    "            'MasterTag': {\n",
    "                'id': cfg['MasterTagId'],\n",
    "                'name': cfg['MasterTagName'],\n",
    "                'values': []\n",
    "            },\n",
    "            'ErrorTag': {\n",
    "                'id': cfg['ErrorTagId'],\n",
    "                'name': cfg['ErrorTagName'],\n",
    "                'values': []\n",
    "            }\n",
    "        }\n",
    "        return cfg_message\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7296ef-4d3c-4059-988e-c959df753826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_cfg_message(messages, tag_name, batch_id, inserted_index):\n",
    "    inserted = False\n",
    "    for m in messages:\n",
    "        if m['BatchId'] == batch_id and m['MasterTag']['name'] == tag_name:\n",
    "            m['MasterTag']['values'].append(inserted_index)\n",
    "            inserted = True\n",
    "        elif m['BatchId'] == batch_id and m['ErrorTag']['name'] == tag_name:\n",
    "            m['ErrorTag']['values'].append(inserted_index)\n",
    "            inserted = True\n",
    "    if not inserted:\n",
    "        tag_message_for_batch = create_tag_message(tag_name, batch_id)\n",
    "        if tag_message_for_batch is not None:\n",
    "            messages.append(tag_message_for_batch)\n",
    "            insert_to_cfg_message(messages, tag_name, batch_id, inserted_index)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ce98fe-9632-478e-8101-d1992783c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(excel_to_read):\n",
    "    csv_dataf = read_excel(get_csv_name(excel_to_read))\n",
    "    messages = []\n",
    "    requires_new_partition = False\n",
    "    for index, row in csv_dataf.iterrows():\n",
    "        batch_name = row['BATCH_ID']\n",
    "        product = row['PRODUCT_ID']\n",
    "        tag_id = row['TAG_ID']\n",
    "        timestamp = row['TIMESTAMP']\n",
    "        value = row['VALUE']\n",
    "        current_partion = sql_operations.get_latest_batch_partition(batch_name)\n",
    "        if not sql_operations.exists_timestamp_value(batch_name, tag_id, timestamp, value):\n",
    "            if value == 0:\n",
    "                sql_operations.insert_new_raw_data( batch_name, product, tag_id, timestamp, value, 'IGNORE')\n",
    "                requires_new_partition = True\n",
    "                if current_partion is not None and current_partion['endTime'] is None:\n",
    "                    sql_operations.finish_batch_partition(current_partion['id'], timestamp)\n",
    "            else:\n",
    "                if requires_new_partition or current_partion is None:\n",
    "                    sql_operations.start_new_batch_partition(batch_name, product, timestamp)\n",
    "                    current_partion = sql_operations.get_latest_batch_partition(batch_name)\n",
    "                    requires_new_partition = False\n",
    "                inserted_id = sql_operations.insert_new_raw_data(\n",
    "                    batch_name, product, tag_id, timestamp, value, 'NEW')\n",
    "                insert_to_cfg_message(messages, tag_id, current_partion['id'], inserted_id)\n",
    "    sql_operations.commit()\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89b9b28-e98f-46ea-a1ce-ee4699fa2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_message(new_records):\n",
    "    for rec in new_records:\n",
    "        channel.basic_publish(\n",
    "            exchange='', routing_key='new_data', body=json.dumps(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5415df9-f895-479e-be1a-63df27335888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name to read unde Generated Folder\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ED1108_1\n"
     ]
    }
   ],
   "source": [
    "print('File name to read unde Generated Folder')\n",
    "file_to_read = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f57c56-c260-4452-8e45-81f7a5d8d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = process_file(file_to_read)\n",
    "publish_message(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45efd4e0-db2d-4658-a0ea-d395b8445ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
